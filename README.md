# RAG-Powered Assistant - Legal Brief Companion

This project implements a modular Retrieval-Augmented Generation (RAG) assistant using LangChain, designed to answer legal and technical queries based on custom documents. It features document ingestion, semantic retrieval, prompt templating, and LLM-backed response generationâ€”all wrapped in a clean CLI and Streamlit interface.

## Project Structure

legal_brief_companion/
â”œâ”€â”€ src
â”‚ â”œâ”€â”€ interface
â”‚ â”‚ â””â”€â”€ cli.py # Command-line interface for user interaction
â”‚ â”œâ”€â”€ ingestion
â”‚ â”‚ â”œâ”€â”€ document_loader.py # Handles loading documents into the application
â”‚ â”‚ â””â”€â”€ text_splitter.py # Splits large documents into smaller chunks
â”‚ â”œâ”€â”€ utils
| â”‚ â””â”€â”€ helpers.py
| legal_brief_companion
â”‚ |
| â”œâ”€â”€ config
â”‚ â”‚ â””â”€â”€ settings.py # Configuration settings for the application
â”‚ â”œâ”€â”€ retrieval
â”‚ â”‚ â”œâ”€â”€ vector_store.py # Manages storage and retrieval of document embeddings
â”‚ â”‚ â””â”€â”€ retriever.py # Fetches relevant documents based on user queries
â”‚ â”œâ”€â”€ llm
â”‚ â”‚ â”œâ”€â”€ chain.py # Orchestrates interaction with the language model
â”‚ | â””â”€â”€ prompt_templates.py # Provides formatted prompt templates
â”‚ |â”€â”€â”€â”€tests
| | |
â”‚ | |â”€â”€ test_ingestion.py
| | â”œâ”€â”€ test_llm.py
| |
â”‚ |â”€â”€â”€â”€â”€â”€â”€**init**.py # Orchestrates interaction with the language model
| |â”€â”€â”€â”€â”€â”€â”€ingest.py
â”œâ”€â”€ data
â”‚ |â”€â”€ documents # Directory for storing custom documents
| | â””â”€â”€Tinker v. Des Moines (8th Cir.).pdf #Document pdf
| |
| |â”€â”€ vector_store
| | â””â”€â”€ 06f38c0e-1645-4d2e-93af-207912a919dd
| | â”œâ”€â”€data_level0.bin
â”‚ | |â”€â”€header.bin
| | â”œâ”€â”€length.bin
â”‚ | â””â”€â”€link_lists.bin
| â””â”€â”€â”€â”€â”€chroma.sqlite3
â”œâ”€â”€ .gitignore
â”œâ”€â”€ poetry.lock
â”œâ”€â”€ pyproject.toml
|â”€â”€ app.py # Main entry point of the application
â”œâ”€â”€ requirements.txt # Python dependencies for the project
â”œâ”€â”€ .env # Environment variables for configuration
â””â”€â”€ README.md # Documentation for the project

```

âš™ï¸ Setup Instructions

1. Clone the repository:

```

git clone <repository-url>
cd legal_brief_companion

```

2. Install the required dependencies:

```

pip install -r requirements.txt

```

3. Set up your environment variables in the `.env` file.
```

GROQ_API_KEY=your_groq_key
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
LLM_PROVIDER=groq
LLM_MODEL=llama-3.1-8b-instant
DATABASE_URL=sqlite:///data/knowledge_base.db
DOCUMENTS_PATH=data/documents
PERSIST_DIRECTORY=data/vector_store
MODEL_NAME=llama3-8b-8192
VECTOR_STORE_TYPE=chroma

debug = true

```
4. Ingest your documents:

```

python run python src/legal_brief_companion/ingest.py

```

5. Ensure the vector store is created in the `data/vector_store` directory.

6. set your Groq Api key in the .env file

```

GROQ_API_KEY=your_api_key_here #power shell

export GROQ_API_KEY=your_api_key_here #linux/mac

```

7. Run the application:

```

python run streamlit run app.py

```

ğŸ§‘â€âš–ï¸ Usage

After running the application, you can interact with the assistant through the command-line interface. Provide your queries, and the assistant will respond based on the ingested documents.

ğŸ§© Components

- Document Ingestion: Load and chunk legal PDFs or text files.

- Vector Store Retrieval: Embed and retrieve relevant chunks using ChromaDB.

- LLM Interaction: Generate answers using Groq-hosted LLaMA models.

- Prompt Templates: Modular prompts for teachable, transparent reasoning.

- User Interface: Streamlit frontend and CLI for flexible interaction.

- Config Management: Pydantic-based .env loader for reproducibility.


ğŸ§ª Testing
Basic unit tests are included under src/legal_brief_companion/tests/. Run with:

pytest src/legal_brief_companion/tests/

ğŸ› ï¸ Built With
[LangChain](https://www.langchain.com/)

[ChromaDB](https://www.chroma.com/)

[Groq](https://www.groq.com/)

[Streamlit](https://streamlit.io/)

[Pydantic](https://pydantic-docs.helpmanual.io/)


ğŸ“¬ Contact
Built by [Getahune Wondemenhu Alemayhu](https://www.github.com/getishe).
For questions, contributions, or collaboration, feel free to reach out or open an issue.

## Contributions are welcome!
  Please open issues or submit pull requests for improvements or bug fixes.
  Please follow the existing code style and include tests for new features.

```
